{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":"DESCENT <p>Optimize force field parameters against reference data</p> <p> </p> <p>The <code>descent</code> framework aims to offer a modern API for training classical force field parameters (either from a  traditional format such as SMIRNOFF or from some ML model) against reference data using <code>pytorch</code>.</p> <p>This framework benefited hugely from ForceBalance, and a significant number of learning from that project, and from Lee-Ping, have influenced the design of this one.</p> <p>Warning: This code is currently experimental and under active development. If you are using this it, please be  aware that it is not guaranteed to provide correct results, the documentation and testing maybe be incomplete, and the API can change without notice.</p>"},{"location":"#installation","title":"Installation","text":"<p>This package can be installed using <code>conda</code> (or <code>mamba</code>, a faster version of <code>conda</code>):</p> <pre><code>mamba install -c conda-forge descent\n</code></pre> <p>The example notebooks further require you install <code>jupyter</code>:</p> <pre><code>mamba install -c conda-forge jupyter\n</code></pre>"},{"location":"#getting-started","title":"Getting Started","text":"<p>To get started, see the examples.</p>"},{"location":"#copyright","title":"Copyright","text":"<p>Copyright (c) 2023, Simon Boothroyd</p>"},{"location":"development/","title":"Development","text":"<p>To create a development environment, you must have <code>mamba</code> installed.</p> <p>A development conda environment can be created and activated with:</p> <pre><code>make env\nconda activate descent\n</code></pre> <p>To format the codebase:</p> <pre><code>make format\n</code></pre> <p>To run the unit tests:</p> <pre><code>make test\n</code></pre> <p>To serve the documentation locally:</p> <pre><code>mkdocs serve\n</code></pre>"},{"location":"reference/","title":"Index","text":""},{"location":"reference/#descent","title":"descent","text":"<p>descent</p> <p>Optimize classical force field parameters against reference data</p> <p>Modules:</p> <ul> <li> <code>optim</code>         \u2013          <p>Custom parameter optimizers.</p> </li> <li> <code>targets</code>         \u2013          <p>Targets to train / assess models to / against.</p> </li> <li> <code>tests</code>         \u2013          </li> <li> <code>utils</code>         \u2013          <p>Utilities functions.</p> </li> </ul>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li> descent<ul> <li> optim</li> <li> targets<ul> <li> dimers</li> <li> energy</li> <li> thermo</li> </ul> </li> <li> utils<ul> <li> dataset</li> <li> loss</li> <li> molecule</li> <li> reporting</li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/optim/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> optim","text":""},{"location":"reference/optim/#descent.optim","title":"optim","text":"<p>Custom parameter optimizers.</p> <p>Classes:</p> <ul> <li> <code>LevenbergMarquardtConfig</code>         \u2013          <p>Configuration for the Levenberg-Marquardt optimizer.</p> </li> </ul> <p>Functions:</p> <ul> <li> <code>levenberg_marquardt</code>           \u2013            <p>Optimize a given set of parameters using the Levenberg-Marquardt algorithm.</p> </li> </ul>"},{"location":"reference/optim/#descent.optim.LevenbergMarquardtConfig","title":"LevenbergMarquardtConfig  <code>pydantic-model</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>Configuration for the Levenberg-Marquardt optimizer.</p> <p>Fields:</p> <ul> <li> <code>type</code>                 (<code>Literal['levenberg-marquardt']</code>)             </li> <li> <code>mode</code>                 (<code>Mode</code>)             </li> <li> <code>trust_radius</code>                 (<code>float</code>)             </li> <li> <code>trust_radius_min</code>                 (<code>float</code>)             </li> <li> <code>min_eigenvalue</code>                 (<code>float</code>)             </li> <li> <code>min_damping_factor</code>                 (<code>float</code>)             </li> <li> <code>adaptive_factor</code>                 (<code>float</code>)             </li> <li> <code>adaptive_damping</code>                 (<code>float</code>)             </li> <li> <code>search_tolerance</code>                 (<code>float</code>)             </li> <li> <code>search_trust_radius_max</code>                 (<code>float</code>)             </li> <li> <code>search_trust_radius_factor</code>                 (<code>float</code>)             </li> <li> <code>error_tolerance</code>                 (<code>float</code>)             </li> <li> <code>quality_threshold_low</code>                 (<code>float</code>)             </li> <li> <code>quality_threshold_high</code>                 (<code>float</code>)             </li> <li> <code>convergence_loss</code>                 (<code>float</code>)             </li> <li> <code>convergence_gradient</code>                 (<code>float</code>)             </li> <li> <code>convergence_step</code>                 (<code>float</code>)             </li> <li> <code>n_convergence_steps</code>                 (<code>int</code>)             </li> <li> <code>n_convergence_criteria</code>                 (<code>int</code>)             </li> <li> <code>max_steps</code>                 (<code>int</code>)             </li> </ul>"},{"location":"reference/optim/#descent.optim.LevenbergMarquardtConfig.mode","title":"mode  <code>pydantic-field</code>","text":"<pre><code>mode: Mode = _ADAPTIVE\n</code></pre> <p>The mode to run the optimizer in.</p>"},{"location":"reference/optim/#descent.optim.LevenbergMarquardtConfig.trust_radius","title":"trust_radius  <code>pydantic-field</code>","text":"<pre><code>trust_radius: float = 0.2\n</code></pre> <p>Target trust radius.</p>"},{"location":"reference/optim/#descent.optim.LevenbergMarquardtConfig.trust_radius_min","title":"trust_radius_min  <code>pydantic-field</code>","text":"<pre><code>trust_radius_min: float = 0.05\n</code></pre> <p>Minimum trust radius.</p>"},{"location":"reference/optim/#descent.optim.LevenbergMarquardtConfig.min_eigenvalue","title":"min_eigenvalue  <code>pydantic-field</code>","text":"<pre><code>min_eigenvalue: float = 0.0001\n</code></pre> <p>Lower bound on hessian eigenvalue. If the smallest eigenvalue is smaller than this, a small amount of steepest descent is mixed in prior to taking a next step to try and correct this.</p>"},{"location":"reference/optim/#descent.optim.LevenbergMarquardtConfig.min_damping_factor","title":"min_damping_factor  <code>pydantic-field</code>","text":"<pre><code>min_damping_factor: float = 1.0\n</code></pre> <p>Minimum damping factor.</p>"},{"location":"reference/optim/#descent.optim.LevenbergMarquardtConfig.adaptive_factor","title":"adaptive_factor  <code>pydantic-field</code>","text":"<pre><code>adaptive_factor: float = 0.25\n</code></pre> <p>Adaptive trust radius adjustment factor to use when running in adaptive mode.</p>"},{"location":"reference/optim/#descent.optim.LevenbergMarquardtConfig.adaptive_damping","title":"adaptive_damping  <code>pydantic-field</code>","text":"<pre><code>adaptive_damping: float = 1.0\n</code></pre> <p>Adaptive trust radius adjustment damping to use when running in adaptive mode.</p>"},{"location":"reference/optim/#descent.optim.LevenbergMarquardtConfig.search_tolerance","title":"search_tolerance  <code>pydantic-field</code>","text":"<pre><code>search_tolerance: float = 0.0001\n</code></pre> <p>The tolerance used when searching for the optimal damping factor with hessian diagonal search (i.e. <code>mode='hessian-search'</code>).</p>"},{"location":"reference/optim/#descent.optim.LevenbergMarquardtConfig.search_trust_radius_max","title":"search_trust_radius_max  <code>pydantic-field</code>","text":"<pre><code>search_trust_radius_max: float = 0.001\n</code></pre> <p>The maximum trust radius to use when falling back to a second line search if the loss would increase after the one.</p>"},{"location":"reference/optim/#descent.optim.LevenbergMarquardtConfig.search_trust_radius_factor","title":"search_trust_radius_factor  <code>pydantic-field</code>","text":"<pre><code>search_trust_radius_factor: float = 0.1\n</code></pre> <p>The factor to scale the trust radius by when falling back to a second line search.</p>"},{"location":"reference/optim/#descent.optim.LevenbergMarquardtConfig.error_tolerance","title":"error_tolerance  <code>pydantic-field</code>","text":"<pre><code>error_tolerance: float = 1.0\n</code></pre> <p>Steps that increase the loss more than this amount are rejected.</p>"},{"location":"reference/optim/#descent.optim.LevenbergMarquardtConfig.quality_threshold_low","title":"quality_threshold_low  <code>pydantic-field</code>","text":"<pre><code>quality_threshold_low: float = 0.25\n</code></pre> <p>The threshold below which the step is considered low quality.</p>"},{"location":"reference/optim/#descent.optim.LevenbergMarquardtConfig.quality_threshold_high","title":"quality_threshold_high  <code>pydantic-field</code>","text":"<pre><code>quality_threshold_high: float = 0.75\n</code></pre> <p>The threshold above which the step is considered high quality.</p>"},{"location":"reference/optim/#descent.optim.LevenbergMarquardtConfig.convergence_loss","title":"convergence_loss  <code>pydantic-field</code>","text":"<pre><code>convergence_loss: float = 0.1\n</code></pre> <p>The loss will be considered converged if its std deviation over the last <code>n_convergence_steps</code> steps is less than this value.</p>"},{"location":"reference/optim/#descent.optim.LevenbergMarquardtConfig.convergence_gradient","title":"convergence_gradient  <code>pydantic-field</code>","text":"<pre><code>convergence_gradient: float = 0.1\n</code></pre> <p>The gradient will be considered converged if its norm is less thanthis value.</p>"},{"location":"reference/optim/#descent.optim.LevenbergMarquardtConfig.convergence_step","title":"convergence_step  <code>pydantic-field</code>","text":"<pre><code>convergence_step: float = 0.01\n</code></pre> <p>The step size will be considered converged if its norm is less than this value.</p>"},{"location":"reference/optim/#descent.optim.LevenbergMarquardtConfig.n_convergence_steps","title":"n_convergence_steps  <code>pydantic-field</code>","text":"<pre><code>n_convergence_steps: int = 2\n</code></pre> <p>The number of steps to consider when checking for convergence in the loss.</p>"},{"location":"reference/optim/#descent.optim.LevenbergMarquardtConfig.n_convergence_criteria","title":"n_convergence_criteria  <code>pydantic-field</code>","text":"<pre><code>n_convergence_criteria: int = 2\n</code></pre> <p>The number of convergence criteria that must be satisfied before the optimization is considered converged. If 0, no convergence criteria will be used and the optimizer will run for <code>max_steps</code> full steps.</p>"},{"location":"reference/optim/#descent.optim.LevenbergMarquardtConfig.max_steps","title":"max_steps  <code>pydantic-field</code>","text":"<pre><code>max_steps: int\n</code></pre> <p>The maximum number of full steps to perform.</p>"},{"location":"reference/optim/#descent.optim.levenberg_marquardt","title":"levenberg_marquardt","text":"<pre><code>levenberg_marquardt(\n    x: Tensor,\n    config: LevenbergMarquardtConfig,\n    closure_fn: ClosureFn,\n    correct_fn: CorrectFn | None = None,\n    report_fn: ReportFn | None = None,\n) -&gt; Tensor\n</code></pre> <p>Optimize a given set of parameters using the Levenberg-Marquardt algorithm.</p> Notes <ul> <li>This optimizer assumes a least-square loss function.</li> <li>This is a reimplementation of the Levenberg-Marquardt optimizer from the   ForceBalance package, and so may differ from a standard implementation.</li> </ul> <p>Parameters:</p> <ul> <li> <code>x</code>             (<code>Tensor</code>)         \u2013          <p>The initial guess of the parameters with <code>shape=(n,)</code>.</p> </li> <li> <code>config</code>             (<code>LevenbergMarquardtConfig</code>)         \u2013          <p>The optimizer config.</p> </li> <li> <code>closure_fn</code>             (<code>ClosureFn</code>)         \u2013          <p>A function that computes the loss (<code>shape=()</code>), its gradient (<code>shape=(n,)</code>), and hessian (<code>shape=(n, n)</code>). It should accept as arguments the current parameter tensor, and two booleans indicating whether the gradient and hessian are required.</p> </li> <li> <code>correct_fn</code>             (<code>CorrectFn | None</code>, default:                 <code>None</code> )         \u2013          <p>A function that can be used to correct the parameters after each step is taken and before the new loss is computed. This may include, for example, ensuring that vdW parameters are all positive. It should accept as arguments the current parameter tensor and return the corrected parameter tensor.</p> </li> <li> <code>report_fn</code>             (<code>ReportFn | None</code>, default:                 <code>None</code> )         \u2013          <p>An optional function that should be called at the end of every step. This can be used to report the current state of the optimization. It should accept as arguments the step number, the current parameter tensor the loss, gradient and hessian, the step 'quality', and a bool indicating whether the step was accepted or rejected.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>         \u2013          <p>The parameters that minimize the loss.</p> </li> </ul> Source code in <code>descent/optim/_lm.py</code> <pre><code>@torch.no_grad()\ndef levenberg_marquardt(\n    x: torch.Tensor,\n    config: LevenbergMarquardtConfig,\n    closure_fn: ClosureFn,\n    correct_fn: CorrectFn | None = None,\n    report_fn: ReportFn | None = None,\n) -&gt; torch.Tensor:\n    \"\"\"Optimize a given set of parameters using the Levenberg-Marquardt algorithm.\n\n    Notes:\n        * This optimizer assumes a least-square loss function.\n        * This is a reimplementation of the Levenberg-Marquardt optimizer from the\n          ForceBalance package, and so may differ from a standard implementation.\n\n    Args:\n        x: The initial guess of the parameters with ``shape=(n,)``.\n        config: The optimizer config.\n        closure_fn: A function that computes the loss (``shape=()``), its\n            gradient (``shape=(n,)``), and hessian (``shape=(n, n)``). It should\n            accept as arguments the current parameter tensor, and two booleans\n            indicating whether the gradient and hessian are required.\n        correct_fn: A function that can be used to correct the parameters after\n            each step is taken and before the new loss is computed. This may\n            include, for example, ensuring that vdW parameters are all positive.\n            It should accept as arguments the current parameter tensor and return\n            the corrected parameter tensor.\n        report_fn: An optional function that should be called at the end of every\n            step. This can be used to report the current state of the optimization.\n            It should accept as arguments the step number, the current parameter tensor\n            the loss, gradient and hessian, the step 'quality', and a bool indicating\n            whether the step was accepted or rejected.\n\n    Returns:\n        The parameters that minimize the loss.\n    \"\"\"\n\n    x = x.clone().detach().requires_grad_(x.requires_grad)\n\n    correct_fn = correct_fn if correct_fn is not None else lambda y: y\n    closure_fn = torch.enable_grad()(closure_fn)\n\n    report_fn = report_fn if report_fn is not None else lambda *_, **__: None\n\n    closure_prev = closure_fn(x, True, True)\n    trust_radius = torch.tensor(config.trust_radius).to(x.device)\n\n    loss_history = []\n    has_converged = False\n\n    best_x, best_loss = x.clone(), closure_prev[0]\n\n    for step in range(config.max_steps):\n        loss_prev, gradient_prev, hessian_prev = closure_prev\n\n        dx, expected_improvement, damping_adjusted, damping_factor = _step(\n            gradient_prev, hessian_prev, trust_radius, config\n        )\n\n        if config.mode.lower() == _HESSIAN_SEARCH:\n            dx, expected_improvement = _hessian_diagonal_search(\n                x,\n                closure_prev,\n                closure_fn,\n                correct_fn,\n                damping_factor,\n                trust_radius,\n                config,\n            )\n\n        dx_norm = torch.linalg.norm(dx)\n        _LOGGER.info(f\"{config.mode} step found (length {dx_norm:.4e})\")\n\n        x_next = correct_fn(x + dx).requires_grad_(x.requires_grad)\n\n        loss, gradient, hessian = closure_fn(x_next, True, True)\n        loss_delta = loss - loss_prev\n\n        step_quality = loss_delta / expected_improvement\n        accept_step = True\n\n        if loss &gt; (loss_prev + config.error_tolerance):\n            # reject the 'bad' step and try again from where we were\n            loss, gradient, hessian = (loss_prev, gradient_prev, hessian_prev)\n            trust_radius = _reduce_trust_radius(dx_norm, config)\n\n            accept_step = False\n        elif config.mode.lower() == _ADAPTIVE:\n            # this was a 'good' step - we can maybe increase the trust radius\n            trust_radius = _update_trust_radius(\n                dx_norm, step_quality, trust_radius, damping_adjusted, config\n            )\n\n        if accept_step:\n            x.data.copy_(x_next.data)\n            loss_history.append(loss.detach().cpu().clone())\n\n        if loss &lt; best_loss:\n            best_x, best_loss = x.clone(), loss.detach().clone()\n\n        closure_prev = (loss, gradient, hessian)\n\n        report_fn(step, x, loss, gradient, hessian, step_quality, accept_step)\n        _LOGGER.info(f\"step={step} loss={loss.detach().cpu().item():.4e}\")\n\n        if _has_converged(dx, loss_history, gradient, step_quality, config):\n            _LOGGER.info(f\"optimization has converged after {step + 1} steps.\")\n            has_converged = True\n\n            break\n\n    if not has_converged:\n        _LOGGER.info(f\"optimization has not converged after {config.max_steps} steps.\")\n\n    return best_x\n</code></pre>"},{"location":"reference/targets/","title":"Index","text":""},{"location":"reference/targets/#descent.targets","title":"targets","text":"<p>Targets to train / assess models to / against.</p> <p>Modules:</p> <ul> <li> <code>dimers</code>         \u2013          <p>Train against dimer energies.</p> </li> <li> <code>energy</code>         \u2013          <p>Train against relative energies and forces.</p> </li> <li> <code>thermo</code>         \u2013          <p>Train against thermodynamic properties.</p> </li> </ul>"},{"location":"reference/targets/dimers/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> dimers","text":""},{"location":"reference/targets/dimers/#descent.targets.dimers","title":"dimers","text":"<p>Train against dimer energies.</p> <p>Classes:</p> <ul> <li> <code>Dimer</code>         \u2013          <p>Represents a single experimental data point.</p> </li> </ul> <p>Functions:</p> <ul> <li> <code>create_dataset</code>           \u2013            <p>Create a dataset from a list of existing dimers.</p> </li> <li> <code>create_from_des</code>           \u2013            <p>Create a dataset from a DESXXX dimer set.</p> </li> <li> <code>extract_smiles</code>           \u2013            <p>Return a list of unique SMILES strings in the dataset.</p> </li> <li> <code>compute_dimer_energy</code>           \u2013            <p>Compute the energy of a dimer in a series of conformers.</p> </li> <li> <code>predict</code>           \u2013            <p>Predict the energies of each dimer in the dataset.</p> </li> <li> <code>report</code>           \u2013            <p>Generate a report comparing the predicted and reference energies of each dimer.</p> </li> </ul>"},{"location":"reference/targets/dimers/#descent.targets.dimers.Dimer","title":"Dimer","text":"<p>             Bases: <code>TypedDict</code></p> <p>Represents a single experimental data point.</p>"},{"location":"reference/targets/dimers/#descent.targets.dimers.create_dataset","title":"create_dataset","text":"<pre><code>create_dataset(dimers: list[Dimer]) -&gt; Dataset\n</code></pre> <p>Create a dataset from a list of existing dimers.</p> <p>Parameters:</p> <ul> <li> <code>dimers</code>             (<code>list[Dimer]</code>)         \u2013          <p>The dimers to create the dataset from.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>         \u2013          <p>The created dataset.</p> </li> </ul> Source code in <code>descent/targets/dimers.py</code> <pre><code>def create_dataset(dimers: list[Dimer]) -&gt; datasets.Dataset:\n    \"\"\"Create a dataset from a list of existing dimers.\n\n    Args:\n        dimers: The dimers to create the dataset from.\n\n    Returns:\n        The created dataset.\n    \"\"\"\n\n    table = pyarrow.Table.from_pylist(\n        [\n            {\n                \"smiles_a\": dimer[\"smiles_a\"],\n                \"smiles_b\": dimer[\"smiles_b\"],\n                \"coords\": torch.tensor(dimer[\"coords\"]).flatten().tolist(),\n                \"energy\": torch.tensor(dimer[\"energy\"]).flatten().tolist(),\n                \"source\": dimer[\"source\"],\n            }\n            for dimer in dimers\n        ],\n        schema=DATA_SCHEMA,\n    )\n    # TODO: validate rows\n    dataset = datasets.Dataset(datasets.table.InMemoryTable(table))\n    dataset.set_format(\"torch\")\n\n    return dataset\n</code></pre>"},{"location":"reference/targets/dimers/#descent.targets.dimers.create_from_des","title":"create_from_des","text":"<pre><code>create_from_des(\n    data_dir: Path, energy_fn: EnergyFn\n) -&gt; Dataset\n</code></pre> <p>Create a dataset from a DESXXX dimer set.</p> <p>Parameters:</p> <ul> <li> <code>data_dir</code>             (<code>Path</code>)         \u2013          <p>The path to the DESXXX directory.</p> </li> <li> <code>energy_fn</code>             (<code>EnergyFn</code>)         \u2013          <p>A function which computes the reference energy of a dimer. This should take as input a pandas DataFrame containing the metadata for a given group, a tuple of geometry IDs, and a tensor of coordinates with <code>shape=(n_dimers, n_atoms, 3)</code>. It should return a tensor of energies with <code>shape=(n_dimers,)</code> and units of [kcal/mol].</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>         \u2013          <p>The created dataset.</p> </li> </ul> Source code in <code>descent/targets/dimers.py</code> <pre><code>def create_from_des(\n    data_dir: pathlib.Path,\n    energy_fn: EnergyFn,\n) -&gt; datasets.Dataset:\n    \"\"\"Create a dataset from a DESXXX dimer set.\n\n    Args:\n        data_dir: The path to the DESXXX directory.\n        energy_fn: A function which computes the reference energy of a dimer. This\n            should take as input a pandas DataFrame containing the metadata for a\n            given group, a tuple of geometry IDs, and a tensor of coordinates with\n            ``shape=(n_dimers, n_atoms, 3)``. It should return a tensor of energies\n            with ``shape=(n_dimers,)`` and units of [kcal/mol].\n\n    Returns:\n        The created dataset.\n    \"\"\"\n    import pandas\n    from rdkit import Chem, RDLogger\n\n    RDLogger.DisableLog(\"rdApp.*\")\n\n    metadata = pandas.read_csv(data_dir / f\"{data_dir.name}.csv\", index_col=False)\n\n    system_ids = metadata[\"system_id\"].unique()\n    dimers: list[Dimer] = []\n\n    for system_id in tqdm.tqdm(system_ids, desc=\"loading dimers\"):\n        system_data = metadata[metadata[\"system_id\"] == system_id]\n\n        group_ids = metadata[metadata[\"system_id\"] == system_id][\"group_id\"].unique()\n\n        for group_id in group_ids:\n            group_data = system_data[system_data[\"group_id\"] == group_id]\n            group_orig = group_data[\"group_orig\"].unique()[0]\n\n            geometry_ids = tuple(group_data[\"geom_id\"].values)\n\n            dimer_example = Chem.MolFromMolFile(\n                f\"{data_dir}/geometries/{system_id}/DES{group_orig}_{geometry_ids[0]}.mol\",\n                removeHs=False,\n            )\n            mol_a, mol_b = Chem.GetMolFrags(dimer_example, asMols=True)\n\n            smiles_a = descent.utils.molecule.mol_to_smiles(mol_a, False)\n            smiles_b = descent.utils.molecule.mol_to_smiles(mol_b, False)\n\n            source = (\n                f\"{data_dir.name} system={system_id} orig={group_orig} group={group_id}\"\n            )\n\n            coords_raw = [\n                Chem.MolFromMolFile(\n                    f\"{data_dir}/geometries/{system_id}/DES{group_orig}_{geometry_id}.mol\",\n                    removeHs=False,\n                )\n                .GetConformer()\n                .GetPositions()\n                .tolist()\n                for geometry_id in geometry_ids\n            ]\n\n            coords = torch.tensor(coords_raw)\n            energy = energy_fn(group_data, geometry_ids, coords)\n\n            dimer = {\n                \"smiles_a\": smiles_a,\n                \"smiles_b\": smiles_b,\n                \"coords\": coords,\n                \"energy\": energy,\n                \"source\": source,\n            }\n            dimers.append(dimer)\n\n    RDLogger.EnableLog(\"rdApp.*\")\n\n    return create_dataset(dimers)\n</code></pre>"},{"location":"reference/targets/dimers/#descent.targets.dimers.extract_smiles","title":"extract_smiles","text":"<pre><code>extract_smiles(dataset: Dataset) -&gt; list[str]\n</code></pre> <p>Return a list of unique SMILES strings in the dataset.</p> <p>Parameters:</p> <ul> <li> <code>dataset</code>             (<code>Dataset</code>)         \u2013          <p>The dataset to extract the SMILES strings from.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[str]</code>         \u2013          <p>The list of unique SMILES strings.</p> </li> </ul> Source code in <code>descent/targets/dimers.py</code> <pre><code>def extract_smiles(dataset: datasets.Dataset) -&gt; list[str]:\n    \"\"\"Return a list of unique SMILES strings in the dataset.\n\n    Args:\n        dataset: The dataset to extract the SMILES strings from.\n\n    Returns:\n        The list of unique SMILES strings.\n    \"\"\"\n\n    smiles_a = dataset.unique(\"smiles_a\")\n    smiles_b = dataset.unique(\"smiles_b\")\n\n    return sorted({*smiles_a, *smiles_b})\n</code></pre>"},{"location":"reference/targets/dimers/#descent.targets.dimers.compute_dimer_energy","title":"compute_dimer_energy","text":"<pre><code>compute_dimer_energy(\n    topology_a: TensorTopology,\n    topology_b: TensorTopology,\n    force_field: TensorForceField,\n    coords: Tensor,\n) -&gt; Tensor\n</code></pre> <p>Compute the energy of a dimer in a series of conformers.</p> <p>Parameters:</p> <ul> <li> <code>topology_a</code>             (<code>TensorTopology</code>)         \u2013          <p>The topology of the first monomer.</p> </li> <li> <code>topology_b</code>             (<code>TensorTopology</code>)         \u2013          <p>The topology of the second monomer.</p> </li> <li> <code>force_field</code>             (<code>TensorForceField</code>)         \u2013          <p>The force field to use.</p> </li> <li> <code>coords</code>             (<code>Tensor</code>)         \u2013          <p>The coordinates of the dimer with <code>shape=(n_dimers, n_atoms, 3)</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>         \u2013          <p>The energy [kcal/mol] of the dimer in each conformer.</p> </li> </ul> Source code in <code>descent/targets/dimers.py</code> <pre><code>def compute_dimer_energy(\n    topology_a: smee.TensorTopology,\n    topology_b: smee.TensorTopology,\n    force_field: smee.TensorForceField,\n    coords: torch.Tensor,\n) -&gt; torch.Tensor:\n    \"\"\"Compute the energy of a dimer in a series of conformers.\n\n    Args:\n        topology_a: The topology of the first monomer.\n        topology_b: The topology of the second monomer.\n        force_field: The force field to use.\n        coords: The coordinates of the dimer with ``shape=(n_dimers, n_atoms, 3)``.\n\n    Returns:\n        The energy [kcal/mol] of the dimer in each conformer.\n    \"\"\"\n    dimer = smee.TensorSystem([topology_a, topology_b], [1, 1], False)\n\n    coords_a = coords[:, : topology_a.n_atoms, :]\n\n    if topology_a.v_sites is not None:\n        coords_a = smee.geometry.add_v_site_coords(\n            topology_a.v_sites, coords_a, force_field\n        )\n\n    coords_b = coords[:, topology_a.n_atoms :, :]\n\n    if topology_b.v_sites is not None:\n        coords_b = smee.geometry.add_v_site_coords(\n            topology_b.v_sites, coords_b, force_field\n        )\n\n    coords = torch.cat([coords_a, coords_b], dim=1)\n\n    energy_dimer = smee.compute_energy(dimer, force_field, coords)\n\n    energy_a = smee.compute_energy(topology_a, force_field, coords_a)\n    energy_b = smee.compute_energy(topology_b, force_field, coords_b)\n\n    return energy_dimer - energy_a - energy_b\n</code></pre>"},{"location":"reference/targets/dimers/#descent.targets.dimers.predict","title":"predict","text":"<pre><code>predict(\n    dataset: Dataset,\n    force_field: TensorForceField,\n    topologies: dict[str, TensorTopology],\n) -&gt; tuple[Tensor, Tensor]\n</code></pre> <p>Predict the energies of each dimer in the dataset.</p> <p>Parameters:</p> <ul> <li> <code>dataset</code>             (<code>Dataset</code>)         \u2013          <p>The dataset to predict the energies of.</p> </li> <li> <code>force_field</code>             (<code>TensorForceField</code>)         \u2013          <p>The force field to use.</p> </li> <li> <code>topologies</code>             (<code>dict[str, TensorTopology]</code>)         \u2013          <p>The topologies of each monomer. Each key should be a fully mapped SMILES string.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[Tensor, Tensor]</code>         \u2013          <p>The reference and predicted energies [kcal/mol] of each dimer, each with <code>shape=(n_dimers * n_conf_per_dimer,)</code>.</p> </li> </ul> Source code in <code>descent/targets/dimers.py</code> <pre><code>def predict(\n    dataset: datasets.Dataset,\n    force_field: smee.TensorForceField,\n    topologies: dict[str, smee.TensorTopology],\n) -&gt; tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"Predict the energies of each dimer in the dataset.\n\n    Args:\n        dataset: The dataset to predict the energies of.\n        force_field: The force field to use.\n        topologies: The topologies of each monomer. Each key should be a fully\n            mapped SMILES string.\n\n    Returns:\n        The reference and predicted energies [kcal/mol] of each dimer, each with\n        ``shape=(n_dimers * n_conf_per_dimer,)``.\n    \"\"\"\n\n    reference, predicted = zip(\n        *[\n            _predict(dimer, force_field, topologies)\n            for dimer in descent.utils.dataset.iter_dataset(dataset)\n        ]\n    )\n    return torch.cat(reference), torch.cat(predicted)\n</code></pre>"},{"location":"reference/targets/dimers/#descent.targets.dimers.report","title":"report","text":"<pre><code>report(\n    dataset: Dataset,\n    force_fields: dict[str, TensorForceField],\n    topologies: dict[str, TensorTopology],\n    output_path: Path,\n)\n</code></pre> <p>Generate a report comparing the predicted and reference energies of each dimer.</p> <p>Parameters:</p> <ul> <li> <code>dataset</code>             (<code>Dataset</code>)         \u2013          <p>The dataset to generate the report for.</p> </li> <li> <code>force_fields</code>             (<code>dict[str, TensorForceField]</code>)         \u2013          <p>The force fields to use to predict the energies.</p> </li> <li> <code>topologies</code>             (<code>dict[str, TensorTopology]</code>)         \u2013          <p>The topologies of each monomer. Each key should be a fully mapped SMILES string.</p> </li> <li> <code>output_path</code>             (<code>Path</code>)         \u2013          <p>The path to write the report to.</p> </li> </ul> Source code in <code>descent/targets/dimers.py</code> <pre><code>def report(\n    dataset: datasets.Dataset,\n    force_fields: dict[str, smee.TensorForceField],\n    topologies: dict[str, smee.TensorTopology],\n    output_path: pathlib.Path,\n):\n    \"\"\"Generate a report comparing the predicted and reference energies of each dimer.\n\n    Args:\n        dataset: The dataset to generate the report for.\n        force_fields: The force fields to use to predict the energies.\n        topologies: The topologies of each monomer. Each key should be a fully\n            mapped SMILES string.\n        output_path: The path to write the report to.\n    \"\"\"\n    import pandas\n\n    rows = []\n\n    delta_sqr_total = {\n        force_field_name: torch.zeros(1) for force_field_name in force_fields\n    }\n    delta_sqr_count = 0\n\n    for dimer in descent.utils.dataset.iter_dataset(dataset):\n        energies = {\"ref\": dimer[\"energy\"]}\n        energies.update(\n            (force_field_name, _predict(dimer, force_field, topologies)[1])\n            for force_field_name, force_field in force_fields.items()\n        )\n\n        mol_img = descent.utils.reporting.mols_to_img(\n            dimer[\"smiles_a\"], dimer[\"smiles_b\"]\n        )\n        data_row = {\"Dimer\": mol_img, \"Energy [kcal/mol]\": _plot_energies(energies)}\n\n        for force_field_name in force_fields:\n            delta_sqr = ((energies[\"ref\"] - energies[force_field_name]) ** 2).sum()\n            delta_sqr_total[force_field_name] += delta_sqr\n\n            rmse = torch.sqrt(delta_sqr / len(energies[\"ref\"]))\n            data_row[f\"RMSE {force_field_name}\"] = rmse.item()\n\n        data_row[\"Source\"] = dimer[\"source\"]\n\n        delta_sqr_count += len(energies[\"ref\"])\n\n        rows.append(data_row)\n\n    rmse_total_rows = [\n        {\n            \"Force Field\": force_field_name,\n            \"RMSE [kcal/mol]\": torch.sqrt(\n                delta_sqr_total[force_field_name].sum() / delta_sqr_count\n            ).item(),\n        }\n        for force_field_name in force_fields\n    ]\n\n    import bokeh.models.widgets.tables\n    import panel\n\n    data_full = pandas.DataFrame(rows)\n    data_stats = pandas.DataFrame(rmse_total_rows)\n\n    rmse_format = bokeh.models.widgets.tables.NumberFormatter(format=\"0.0000\")\n\n    formatters_stats = {\n        col: rmse_format for col in data_stats.columns if col.startswith(\"RMSE\")\n    }\n    formatters_full = {\n        **{col: \"html\" for col in [\"Dimer\", \"Energy [kcal/mol]\"]},\n        **{col: rmse_format for col in data_full.columns if col.startswith(\"RMSE\")},\n    }\n\n    layout = panel.Column(\n        \"## Statistics\",\n        panel.widgets.Tabulator(\n            pandas.DataFrame(rmse_total_rows),\n            show_index=False,\n            selectable=False,\n            disabled=True,\n            formatters=formatters_stats,\n            configuration={\"columnDefaults\": {\"headerSort\": False}},\n        ),\n        \"## Energies\",\n        panel.widgets.Tabulator(\n            data_full,\n            show_index=False,\n            selectable=False,\n            disabled=True,\n            formatters=formatters_full,\n            configuration={\"rowHeight\": 400},\n        ),\n        sizing_mode=\"stretch_width\",\n        scroll=True,\n    )\n\n    output_path.parent.mkdir(parents=True, exist_ok=True)\n    layout.save(output_path, title=\"Dimers\", embed=True)\n</code></pre>"},{"location":"reference/targets/energy/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> energy","text":""},{"location":"reference/targets/energy/#descent.targets.energy","title":"energy","text":"<p>Train against relative energies and forces.</p> <p>Classes:</p> <ul> <li> <code>Entry</code>         \u2013          <p>Represents a set of reference energies and forces.</p> </li> </ul> <p>Functions:</p> <ul> <li> <code>create_dataset</code>           \u2013            <p>Create a dataset from a list of existing entries.</p> </li> <li> <code>extract_smiles</code>           \u2013            <p>Return a list of unique SMILES strings in the dataset.</p> </li> <li> <code>predict</code>           \u2013            <p>Predict the relative energies [kcal/mol] and forces [kcal/mol/\u00c5] of a dataset.</p> </li> </ul>"},{"location":"reference/targets/energy/#descent.targets.energy.Entry","title":"Entry","text":"<p>             Bases: <code>TypedDict</code></p> <p>Represents a set of reference energies and forces.</p> <p>Attributes:</p> <ul> <li> <code>smiles</code>             (<code>str</code>)         \u2013          <p>The indexed SMILES description of the molecule the energies and forces were</p> </li> <li> <code>coords</code>             (<code>Tensor</code>)         \u2013          <p>The coordinates [\u00c5] the energies and forces were evaluated at with</p> </li> <li> <code>energy</code>             (<code>Tensor</code>)         \u2013          <p>The reference energies [kcal/mol] with <code>shape=(n_confs,)</code>.</p> </li> <li> <code>forces</code>             (<code>Tensor</code>)         \u2013          <p>The reference forces [kcal/mol/\u00c5] with <code>shape=(n_confs, n_particles, 3)</code>.</p> </li> </ul>"},{"location":"reference/targets/energy/#descent.targets.energy.Entry.smiles","title":"smiles  <code>instance-attribute</code>","text":"<pre><code>smiles: str\n</code></pre> <p>The indexed SMILES description of the molecule the energies and forces were computed for.</p>"},{"location":"reference/targets/energy/#descent.targets.energy.Entry.coords","title":"coords  <code>instance-attribute</code>","text":"<pre><code>coords: Tensor\n</code></pre> <p>The coordinates [\u00c5] the energies and forces were evaluated at with <code>shape=(n_confs, n_particles, 3)</code>.</p>"},{"location":"reference/targets/energy/#descent.targets.energy.Entry.energy","title":"energy  <code>instance-attribute</code>","text":"<pre><code>energy: Tensor\n</code></pre> <p>The reference energies [kcal/mol] with <code>shape=(n_confs,)</code>.</p>"},{"location":"reference/targets/energy/#descent.targets.energy.Entry.forces","title":"forces  <code>instance-attribute</code>","text":"<pre><code>forces: Tensor\n</code></pre> <p>The reference forces [kcal/mol/\u00c5] with <code>shape=(n_confs, n_particles, 3)</code>.</p>"},{"location":"reference/targets/energy/#descent.targets.energy.create_dataset","title":"create_dataset","text":"<pre><code>create_dataset(entries: list[Entry]) -&gt; Dataset\n</code></pre> <p>Create a dataset from a list of existing entries.</p> <p>Parameters:</p> <ul> <li> <code>entries</code>             (<code>list[Entry]</code>)         \u2013          <p>The entries to create the dataset from.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>         \u2013          <p>The created dataset.</p> </li> </ul> Source code in <code>descent/targets/energy.py</code> <pre><code>def create_dataset(entries: list[Entry]) -&gt; datasets.Dataset:\n    \"\"\"Create a dataset from a list of existing entries.\n\n    Args:\n        entries: The entries to create the dataset from.\n\n    Returns:\n        The created dataset.\n    \"\"\"\n\n    table = pyarrow.Table.from_pylist(\n        [\n            {\n                \"smiles\": entry[\"smiles\"],\n                \"coords\": torch.tensor(entry[\"coords\"]).flatten().tolist(),\n                \"energy\": torch.tensor(entry[\"energy\"]).flatten().tolist(),\n                \"forces\": torch.tensor(entry[\"forces\"]).flatten().tolist(),\n            }\n            for entry in entries\n        ],\n        schema=DATA_SCHEMA,\n    )\n    # TODO: validate rows\n    dataset = datasets.Dataset(datasets.table.InMemoryTable(table))\n    dataset.set_format(\"torch\")\n\n    return dataset\n</code></pre>"},{"location":"reference/targets/energy/#descent.targets.energy.extract_smiles","title":"extract_smiles","text":"<pre><code>extract_smiles(dataset: Dataset) -&gt; list[str]\n</code></pre> <p>Return a list of unique SMILES strings in the dataset.</p> <p>Parameters:</p> <ul> <li> <code>dataset</code>             (<code>Dataset</code>)         \u2013          <p>The dataset to extract the SMILES strings from.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[str]</code>         \u2013          <p>The list of unique SMILES strings.</p> </li> </ul> Source code in <code>descent/targets/energy.py</code> <pre><code>def extract_smiles(dataset: datasets.Dataset) -&gt; list[str]:\n    \"\"\"Return a list of unique SMILES strings in the dataset.\n\n    Args:\n        dataset: The dataset to extract the SMILES strings from.\n\n    Returns:\n        The list of unique SMILES strings.\n    \"\"\"\n    return sorted({*dataset.unique(\"smiles\")})\n</code></pre>"},{"location":"reference/targets/energy/#descent.targets.energy.predict","title":"predict","text":"<pre><code>predict(\n    dataset: Dataset,\n    force_field: TensorForceField,\n    topologies: dict[str, TensorTopology],\n    reference: Literal[\"mean\", \"min\"] = \"mean\",\n    normalize: bool = True,\n) -&gt; tuple[Tensor, Tensor, Tensor, Tensor]\n</code></pre> <p>Predict the relative energies [kcal/mol] and forces [kcal/mol/\u00c5] of a dataset.</p> <p>Parameters:</p> <ul> <li> <code>dataset</code>             (<code>Dataset</code>)         \u2013          <p>The dataset to predict the energies and forces of.</p> </li> <li> <code>force_field</code>             (<code>TensorForceField</code>)         \u2013          <p>The force field to use to predict the energies and forces.</p> </li> <li> <code>topologies</code>             (<code>dict[str, TensorTopology]</code>)         \u2013          <p>The topologies of the molecules in the dataset. Each key should be a fully indexed SMILES string.</p> </li> <li> <code>reference</code>             (<code>Literal['mean', 'min']</code>, default:                 <code>'mean'</code> )         \u2013          <p>The reference energy to compute the relative energies with respect to. This should be either the \"mean\" energy of all conformers, or the energy of the conformer with the lowest reference energy (\"min\").</p> </li> <li> <code>normalize</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to scale the relative energies by <code>1/sqrt(n_confs_i)</code> and the forces by <code>1/sqrt(n_confs_i * n_atoms_per_conf_i * 3)</code> This is useful when wanting to compute the MSE per entry.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[Tensor, Tensor, Tensor, Tensor]</code>         \u2013          <p>The predicted and reference relative energies [kcal/mol] with <code>shape=(n_confs,)</code>, and predicted and reference forces [kcal/mol/\u00c5] with <code>shape=(n_confs * n_atoms_per_conf, 3)</code>.</p> </li> </ul> Source code in <code>descent/targets/energy.py</code> <pre><code>def predict(\n    dataset: datasets.Dataset,\n    force_field: smee.TensorForceField,\n    topologies: dict[str, smee.TensorTopology],\n    reference: typing.Literal[\"mean\", \"min\"] = \"mean\",\n    normalize: bool = True,\n) -&gt; tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"Predict the relative energies [kcal/mol] and forces [kcal/mol/\u00c5] of a dataset.\n\n    Args:\n        dataset: The dataset to predict the energies and forces of.\n        force_field: The force field to use to predict the energies and forces.\n        topologies: The topologies of the molecules in the dataset. Each key should be\n            a fully indexed SMILES string.\n        reference: The reference energy to compute the relative energies with respect\n            to. This should be either the \"mean\" energy of all conformers, or the\n            energy of the conformer with the lowest reference energy (\"min\").\n        normalize: Whether to scale the relative energies by ``1/sqrt(n_confs_i)``\n            and the forces by ``1/sqrt(n_confs_i * n_atoms_per_conf_i * 3)`` This\n            is useful when wanting to compute the MSE per entry.\n\n    Returns:\n        The predicted and reference relative energies [kcal/mol] with\n        ``shape=(n_confs,)``, and predicted and reference forces [kcal/mol/\u00c5] with\n        ``shape=(n_confs * n_atoms_per_conf, 3)``.\n    \"\"\"\n    energy_ref_all, energy_pred_all = [], []\n    forces_ref_all, forces_pred_all = [], []\n\n    for entry in dataset:\n        smiles = entry[\"smiles\"]\n\n        energy_ref = entry[\"energy\"]\n        forces_ref = entry[\"forces\"].reshape(len(energy_ref), -1, 3)\n\n        coords = (\n            entry[\"coords\"]\n            .reshape(len(energy_ref), -1, 3)\n            .detach()\n            .requires_grad_(True)\n        )\n        topology = topologies[smiles]\n\n        energy_pred = smee.compute_energy(topology, force_field, coords)\n        forces_pred = torch.autograd.grad(\n            energy_pred.sum(),\n            coords,\n            create_graph=True,\n            retain_graph=True,\n            allow_unused=True,\n        )[0]\n\n        if reference.lower() == \"mean\":\n            energy_ref_0 = energy_ref.mean()\n            energy_pred_0 = energy_pred.mean()\n        elif reference.lower() == \"min\":\n            min_idx = energy_ref.argmin()\n\n            energy_ref_0 = energy_ref[min_idx]\n            energy_pred_0 = energy_pred[min_idx]\n        else:\n            raise NotImplementedError(f\"invalid reference energy {reference}\")\n\n        scale_energy, scale_forces = 1.0, 1.0\n\n        if normalize:\n            scale_energy = 1.0 / torch.sqrt(torch.tensor(energy_pred.numel()))\n            scale_forces = 1.0 / torch.sqrt(torch.tensor(forces_pred.numel()))\n\n        energy_ref_all.append(scale_energy * (energy_ref - energy_ref_0))\n        forces_ref_all.append(scale_forces * forces_ref.reshape(-1, 3))\n\n        energy_pred_all.append(scale_energy * (energy_pred - energy_pred_0))\n        forces_pred_all.append(scale_forces * forces_pred.reshape(-1, 3))\n\n    return (\n        torch.cat(energy_ref_all),\n        torch.cat(energy_pred_all),\n        torch.cat(forces_ref_all),\n        torch.cat(forces_pred_all),\n    )\n</code></pre>"},{"location":"reference/targets/thermo/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> thermo","text":""},{"location":"reference/targets/thermo/#descent.targets.thermo","title":"thermo","text":"<p>Train against thermodynamic properties.</p> <p>Classes:</p> <ul> <li> <code>DataEntry</code>         \u2013          <p>Represents a single experimental data point.</p> </li> <li> <code>SimulationKey</code>         \u2013          <p>A key used to identify a simulation.</p> </li> <li> <code>SimulationConfig</code>         \u2013          <p>Configuration for a simulation to run.</p> </li> </ul> <p>Functions:</p> <ul> <li> <code>create_dataset</code>           \u2013            <p>Create a dataset from a list of existing data points.</p> </li> <li> <code>extract_smiles</code>           \u2013            <p>Return a list of unique SMILES strings in the dataset.</p> </li> <li> <code>default_config</code>           \u2013            <p>Return a default simulation configuration for the specified phase.</p> </li> <li> <code>predict</code>           \u2013            <p>Predict the properties in a dataset using molecular simulation, or by reweighting</p> </li> </ul>"},{"location":"reference/targets/thermo/#descent.targets.thermo.DataEntry","title":"DataEntry","text":"<p>             Bases: <code>TypedDict</code></p> <p>Represents a single experimental data point.</p> <p>Attributes:</p> <ul> <li> <code>type</code>             (<code>DataType</code>)         \u2013          <p>The type of data point.</p> </li> <li> <code>smiles_a</code>             (<code>str</code>)         \u2013          <p>The SMILES definition of the first component.</p> </li> <li> <code>x_a</code>             (<code>float | None</code>)         \u2013          <p>The mole fraction of the first component. This must be set to 1.0 if the data</p> </li> <li> <code>smiles_b</code>             (<code>str | None</code>)         \u2013          <p>The SMILES definition of the second component if present.</p> </li> <li> <code>x_b</code>             (<code>float | None</code>)         \u2013          <p>The mole fraction of the second component if present.</p> </li> <li> <code>temperature</code>             (<code>float</code>)         \u2013          <p>The temperature at which the data point was measured.</p> </li> <li> <code>pressure</code>             (<code>float</code>)         \u2013          <p>The pressure at which the data point was measured.</p> </li> <li> <code>value</code>             (<code>float</code>)         \u2013          <p>The value of the data point.</p> </li> <li> <code>std</code>             (<code>float | None</code>)         \u2013          <p>The standard deviation of the data point if available.</p> </li> <li> <code>units</code>             (<code>str</code>)         \u2013          <p>The units of the data point.</p> </li> <li> <code>source</code>             (<code>str</code>)         \u2013          <p>The source of the data point.</p> </li> </ul>"},{"location":"reference/targets/thermo/#descent.targets.thermo.DataEntry.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: DataType\n</code></pre> <p>The type of data point.</p>"},{"location":"reference/targets/thermo/#descent.targets.thermo.DataEntry.smiles_a","title":"smiles_a  <code>instance-attribute</code>","text":"<pre><code>smiles_a: str\n</code></pre> <p>The SMILES definition of the first component.</p>"},{"location":"reference/targets/thermo/#descent.targets.thermo.DataEntry.x_a","title":"x_a  <code>instance-attribute</code>","text":"<pre><code>x_a: float | None\n</code></pre> <p>The mole fraction of the first component. This must be set to 1.0 if the data</p>"},{"location":"reference/targets/thermo/#descent.targets.thermo.DataEntry.smiles_b","title":"smiles_b  <code>instance-attribute</code>","text":"<pre><code>smiles_b: str | None\n</code></pre> <p>The SMILES definition of the second component if present.</p>"},{"location":"reference/targets/thermo/#descent.targets.thermo.DataEntry.x_b","title":"x_b  <code>instance-attribute</code>","text":"<pre><code>x_b: float | None\n</code></pre> <p>The mole fraction of the second component if present.</p>"},{"location":"reference/targets/thermo/#descent.targets.thermo.DataEntry.temperature","title":"temperature  <code>instance-attribute</code>","text":"<pre><code>temperature: float\n</code></pre> <p>The temperature at which the data point was measured.</p>"},{"location":"reference/targets/thermo/#descent.targets.thermo.DataEntry.pressure","title":"pressure  <code>instance-attribute</code>","text":"<pre><code>pressure: float\n</code></pre> <p>The pressure at which the data point was measured.</p>"},{"location":"reference/targets/thermo/#descent.targets.thermo.DataEntry.value","title":"value  <code>instance-attribute</code>","text":"<pre><code>value: float\n</code></pre> <p>The value of the data point.</p>"},{"location":"reference/targets/thermo/#descent.targets.thermo.DataEntry.std","title":"std  <code>instance-attribute</code>","text":"<pre><code>std: float | None\n</code></pre> <p>The standard deviation of the data point if available.</p>"},{"location":"reference/targets/thermo/#descent.targets.thermo.DataEntry.units","title":"units  <code>instance-attribute</code>","text":"<pre><code>units: str\n</code></pre> <p>The units of the data point.</p>"},{"location":"reference/targets/thermo/#descent.targets.thermo.DataEntry.source","title":"source  <code>instance-attribute</code>","text":"<pre><code>source: str\n</code></pre> <p>The source of the data point.</p>"},{"location":"reference/targets/thermo/#descent.targets.thermo.SimulationKey","title":"SimulationKey","text":"<p>             Bases: <code>NamedTuple</code></p> <p>A key used to identify a simulation.</p> <p>Attributes:</p> <ul> <li> <code>smiles</code>             (<code>tuple[str, ...]</code>)         \u2013          <p>The SMILES definitions of the components present in the system.</p> </li> <li> <code>counts</code>             (<code>tuple[int, ...]</code>)         \u2013          <p>The number of copies of each component present in the system.</p> </li> <li> <code>temperature</code>             (<code>float</code>)         \u2013          <p>The temperature [K] at which the simulation was run.</p> </li> <li> <code>pressure</code>             (<code>float | None</code>)         \u2013          <p>The pressure [atm] at which the simulation was run.</p> </li> </ul>"},{"location":"reference/targets/thermo/#descent.targets.thermo.SimulationKey.smiles","title":"smiles  <code>instance-attribute</code>","text":"<pre><code>smiles: tuple[str, ...]\n</code></pre> <p>The SMILES definitions of the components present in the system.</p>"},{"location":"reference/targets/thermo/#descent.targets.thermo.SimulationKey.counts","title":"counts  <code>instance-attribute</code>","text":"<pre><code>counts: tuple[int, ...]\n</code></pre> <p>The number of copies of each component present in the system.</p>"},{"location":"reference/targets/thermo/#descent.targets.thermo.SimulationKey.temperature","title":"temperature  <code>instance-attribute</code>","text":"<pre><code>temperature: float\n</code></pre> <p>The temperature [K] at which the simulation was run.</p>"},{"location":"reference/targets/thermo/#descent.targets.thermo.SimulationKey.pressure","title":"pressure  <code>instance-attribute</code>","text":"<pre><code>pressure: float | None\n</code></pre> <p>The pressure [atm] at which the simulation was run.</p>"},{"location":"reference/targets/thermo/#descent.targets.thermo.SimulationConfig","title":"SimulationConfig  <code>pydantic-model</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>Configuration for a simulation to run.</p> <p>Fields:</p> <ul> <li> <code>max_mols</code>                 (<code>int</code>)             </li> <li> <code>gen_coords</code>                 (<code>GenerateCoordsConfig</code>)             </li> <li> <code>apply_hmr</code>                 (<code>bool</code>)             </li> <li> <code>equilibrate</code>                 (<code>list[MinimizationConfig | SimulationConfig]</code>)             </li> <li> <code>production</code>                 (<code>SimulationConfig</code>)             </li> <li> <code>production_frequency</code>                 (<code>int</code>)             </li> </ul>"},{"location":"reference/targets/thermo/#descent.targets.thermo.SimulationConfig.max_mols","title":"max_mols  <code>pydantic-field</code>","text":"<pre><code>max_mols: int\n</code></pre> <p>The maximum number of molecules to simulate.</p>"},{"location":"reference/targets/thermo/#descent.targets.thermo.SimulationConfig.gen_coords","title":"gen_coords  <code>pydantic-field</code>","text":"<pre><code>gen_coords: GenerateCoordsConfig\n</code></pre> <p>Configuration for generating initial coordinates.</p>"},{"location":"reference/targets/thermo/#descent.targets.thermo.SimulationConfig.apply_hmr","title":"apply_hmr  <code>pydantic-field</code>","text":"<pre><code>apply_hmr: bool = False\n</code></pre> <p>Whether to apply hydrogen mass repartitioning.</p>"},{"location":"reference/targets/thermo/#descent.targets.thermo.SimulationConfig.equilibrate","title":"equilibrate  <code>pydantic-field</code>","text":"<pre><code>equilibrate: list[MinimizationConfig | SimulationConfig]\n</code></pre> <p>Configuration for equilibration simulations.</p>"},{"location":"reference/targets/thermo/#descent.targets.thermo.SimulationConfig.production","title":"production  <code>pydantic-field</code>","text":"<pre><code>production: SimulationConfig\n</code></pre> <p>Configuration for the production simulation.</p>"},{"location":"reference/targets/thermo/#descent.targets.thermo.SimulationConfig.production_frequency","title":"production_frequency  <code>pydantic-field</code>","text":"<pre><code>production_frequency: int\n</code></pre> <p>The frequency at which to write frames during production.</p>"},{"location":"reference/targets/thermo/#descent.targets.thermo.create_dataset","title":"create_dataset","text":"<pre><code>create_dataset(*rows: DataEntry) -&gt; Dataset\n</code></pre> <p>Create a dataset from a list of existing data points.</p> <p>Parameters:</p> <ul> <li> <code>rows</code>             (<code>DataEntry</code>, default:                 <code>()</code> )         \u2013          <p>The data points to create the dataset from.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>         \u2013          <p>The created dataset.</p> </li> </ul> Source code in <code>descent/targets/thermo.py</code> <pre><code>def create_dataset(*rows: DataEntry) -&gt; datasets.Dataset:\n    \"\"\"Create a dataset from a list of existing data points.\n\n    Args:\n        rows: The data points to create the dataset from.\n\n    Returns:\n        The created dataset.\n    \"\"\"\n\n    for row in rows:\n        row[\"smiles_a\"] = Chem.MolToSmiles(Chem.MolFromSmiles(row[\"smiles_a\"]))\n\n        if row[\"smiles_b\"] is None:\n            continue\n\n        row[\"smiles_b\"] = Chem.MolToSmiles(Chem.MolFromSmiles(row[\"smiles_b\"]))\n\n    # TODO: validate rows\n    table = pyarrow.Table.from_pylist([*rows], schema=DATA_SCHEMA)\n\n    dataset = datasets.Dataset(datasets.table.InMemoryTable(table))\n    return dataset\n</code></pre>"},{"location":"reference/targets/thermo/#descent.targets.thermo.extract_smiles","title":"extract_smiles","text":"<pre><code>extract_smiles(dataset: Dataset) -&gt; list[str]\n</code></pre> <p>Return a list of unique SMILES strings in the dataset.</p> <p>Parameters:</p> <ul> <li> <code>dataset</code>             (<code>Dataset</code>)         \u2013          <p>The dataset to extract the SMILES strings from.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[str]</code>         \u2013          <p>The unique SMILES strings with full atom mapping.</p> </li> </ul> Source code in <code>descent/targets/thermo.py</code> <pre><code>def extract_smiles(dataset: datasets.Dataset) -&gt; list[str]:\n    \"\"\"Return a list of unique SMILES strings in the dataset.\n\n    Args:\n        dataset: The dataset to extract the SMILES strings from.\n\n    Returns:\n        The unique SMILES strings with full atom mapping.\n    \"\"\"\n    smiles_a = {smiles for smiles in dataset.unique(\"smiles_a\") if smiles is not None}\n    smiles_b = {smiles for smiles in dataset.unique(\"smiles_b\") if smiles is not None}\n\n    smiles_unique = sorted({*smiles_a, *smiles_b})\n    return smiles_unique\n</code></pre>"},{"location":"reference/targets/thermo/#descent.targets.thermo.default_config","title":"default_config","text":"<pre><code>default_config(\n    phase: Phase, temperature: float, pressure: float | None\n) -&gt; SimulationConfig\n</code></pre> <p>Return a default simulation configuration for the specified phase.</p> <p>Parameters:</p> <ul> <li> <code>phase</code>             (<code>Phase</code>)         \u2013          <p>The phase to return the default configuration for.</p> </li> <li> <code>temperature</code>             (<code>float</code>)         \u2013          <p>The temperature [K] at which to run the simulation.</p> </li> <li> <code>pressure</code>             (<code>float | None</code>)         \u2013          <p>The pressure [atm] at which to run the simulation.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>SimulationConfig</code>         \u2013          <p>The default simulation configuration.</p> </li> </ul> Source code in <code>descent/targets/thermo.py</code> <pre><code>def default_config(\n    phase: Phase, temperature: float, pressure: float | None\n) -&gt; SimulationConfig:\n    \"\"\"Return a default simulation configuration for the specified phase.\n\n    Args:\n        phase: The phase to return the default configuration for.\n        temperature: The temperature [K] at which to run the simulation.\n        pressure: The pressure [atm] at which to run the simulation.\n\n    Returns:\n        The default simulation configuration.\n    \"\"\"\n\n    if phase.lower() == \"bulk\":\n        return _bulk_config(temperature, pressure)\n    elif phase.lower() == \"vacuum\":\n        return _vacuum_config(temperature, pressure)\n    else:\n        raise NotImplementedError(phase)\n</code></pre>"},{"location":"reference/targets/thermo/#descent.targets.thermo.predict","title":"predict","text":"<pre><code>predict(\n    dataset: Dataset,\n    force_field: TensorForceField,\n    topologies: dict[str, TensorTopology],\n    output_dir: Path,\n    cached_dir: Path | None = None,\n    per_type_scales: dict[DataType, float] | None = None,\n) -&gt; tuple[Tensor, Tensor, Tensor, Tensor]\n</code></pre> <p>Predict the properties in a dataset using molecular simulation, or by reweighting previous simulation data.</p> <p>Parameters:</p> <ul> <li> <code>dataset</code>             (<code>Dataset</code>)         \u2013          <p>The dataset to predict the properties of.</p> </li> <li> <code>force_field</code>             (<code>TensorForceField</code>)         \u2013          <p>The force field to use.</p> </li> <li> <code>topologies</code>             (<code>dict[str, TensorTopology]</code>)         \u2013          <p>The topologies of the molecules present in the dataset, with keys of mapped SMILES patterns.</p> </li> <li> <code>output_dir</code>             (<code>Path</code>)         \u2013          <p>The directory to write the simulation trajectories to.</p> </li> <li> <code>cached_dir</code>             (<code>Path | None</code>, default:                 <code>None</code> )         \u2013          <p>The (optional) directory to read cached simulation trajectories from.</p> </li> <li> <code>per_type_scales</code>             (<code>dict[DataType, float] | None</code>, default:                 <code>None</code> )         \u2013          <p>The scale factor to apply to each data type. A default of 1.0 will be used for any data type not specified.</p> </li> </ul> Source code in <code>descent/targets/thermo.py</code> <pre><code>def predict(\n    dataset: datasets.Dataset,\n    force_field: smee.TensorForceField,\n    topologies: dict[str, smee.TensorTopology],\n    output_dir: pathlib.Path,\n    cached_dir: pathlib.Path | None = None,\n    per_type_scales: dict[DataType, float] | None = None,\n) -&gt; tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"Predict the properties in a dataset using molecular simulation, or by reweighting\n    previous simulation data.\n\n    Args:\n        dataset: The dataset to predict the properties of.\n        force_field: The force field to use.\n        topologies: The topologies of the molecules present in the dataset, with keys\n            of mapped SMILES patterns.\n        output_dir: The directory to write the simulation trajectories to.\n        cached_dir: The (optional) directory to read cached simulation trajectories\n            from.\n        per_type_scales: The scale factor to apply to each data type. A default of 1.0\n            will be used for any data type not specified.\n    \"\"\"\n\n    entries: list[DataEntry] = [*descent.utils.dataset.iter_dataset(dataset)]\n\n    required_simulations, entry_to_simulation = _plan_simulations(entries, topologies)\n    observables = {\n        phase: {\n            key: _compute_observables(\n                phase, key, system, force_field, output_dir, cached_dir\n            )\n            for key, system in systems.items()\n        }\n        for phase, systems in required_simulations.items()\n    }\n\n    predicted = []\n    predicted_std = []\n    reference = []\n    reference_std = []\n\n    per_type_scales = per_type_scales if per_type_scales is not None else {}\n\n    for entry, keys in zip(entries, entry_to_simulation):\n        value, std = _predict(entry, keys, observables, required_simulations)\n\n        type_scale = per_type_scales.get(entry[\"type\"], 1.0)\n\n        predicted.append(value * type_scale)\n        predicted_std.append(torch.nan if std is None else std * abs(type_scale))\n\n        reference.append(entry[\"value\"] * type_scale)\n        reference_std.append(\n            torch.nan if entry[\"std\"] is None else entry[\"std\"] * abs(type_scale)\n        )\n\n    predicted = torch.stack(predicted)\n    predicted_std = torch.stack(predicted_std)\n\n    reference = smee.utils.tensor_like(reference, predicted)\n    reference_std = smee.utils.tensor_like(reference_std, predicted_std)\n\n    return reference, reference_std, predicted, predicted_std\n</code></pre>"},{"location":"reference/utils/","title":"Index","text":""},{"location":"reference/utils/#descent.utils","title":"utils","text":"<p>Utilities functions.</p> <p>Modules:</p> <ul> <li> <code>dataset</code>         \u2013          <p>Utilities for working with datasets.</p> </li> <li> <code>loss</code>         \u2013          <p>Utilities for defining loss functions.</p> </li> <li> <code>molecule</code>         \u2013          </li> <li> <code>reporting</code>         \u2013          <p>Utilities for reporting results.</p> </li> </ul>"},{"location":"reference/utils/dataset/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> dataset","text":""},{"location":"reference/utils/dataset/#descent.utils.dataset","title":"dataset","text":"<p>Utilities for working with datasets.</p> <p>Functions:</p> <ul> <li> <code>iter_dataset</code>           \u2013            <p>Iterate over a Hugging Face Dataset, yielding each 'row' as a dictionary.</p> </li> </ul>"},{"location":"reference/utils/dataset/#descent.utils.dataset.iter_dataset","title":"iter_dataset","text":"<pre><code>iter_dataset(dataset: Dataset) -&gt; Iterator[dict[str, Any]]\n</code></pre> <p>Iterate over a Hugging Face Dataset, yielding each 'row' as a dictionary.</p> <p>Parameters:</p> <ul> <li> <code>dataset</code>             (<code>Dataset</code>)         \u2013          <p>The dataset to iterate over.</p> </li> </ul> <p>Yields:</p> <ul> <li> <code>dict[str, Any]</code>         \u2013          <p>A dictionary representing a single entry in the batch, where each key is a</p> </li> <li> <code>dict[str, Any]</code>         \u2013          <p>column name and the corresponding value is the entry in that column for the</p> </li> <li> <code>dict[str, Any]</code>         \u2013          <p>current row.</p> </li> </ul> Source code in <code>descent/utils/dataset.py</code> <pre><code>def iter_dataset(dataset: datasets.Dataset) -&gt; typing.Iterator[dict[str, typing.Any]]:\n    \"\"\"Iterate over a Hugging Face Dataset, yielding each 'row' as a dictionary.\n\n    Args:\n        dataset: The dataset to iterate over.\n\n    Yields:\n        A dictionary representing a single entry in the batch, where each key is a\n        column name and the corresponding value is the entry in that column for the\n        current row.\n    \"\"\"\n\n    columns = [*dataset.features]\n\n    for row in zip(*[dataset[column] for column in columns]):\n        yield {column: v for column, v in zip(columns, row)}\n</code></pre>"},{"location":"reference/utils/loss/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> loss","text":""},{"location":"reference/utils/loss/#descent.utils.loss","title":"loss","text":"<p>Utilities for defining loss functions.</p> <p>Functions:</p> <ul> <li> <code>to_closure</code>           \u2013            <p>Convert a loss function to a closure function used by second-order optimizers.</p> </li> <li> <code>approximate_hessian</code>           \u2013            <p>Compute the outer product approximation of the hessian of a least squares</p> </li> </ul>"},{"location":"reference/utils/loss/#descent.utils.loss.to_closure","title":"to_closure","text":"<pre><code>to_closure(\n    loss_fn: Callable[Concatenate[Tensor, P], Tensor],\n    *args: args,\n    **kwargs: kwargs\n) -&gt; ClosureFn\n</code></pre> <p>Convert a loss function to a closure function used by second-order optimizers.</p> <p>Parameters:</p> <ul> <li> <code>loss_fn</code>             (<code>Callable[Concatenate[Tensor, P], Tensor]</code>)         \u2013          <p>The loss function to convert. This should take in a tensor of parameters with <code>shape=(n,)</code>, and optionally a set of <code>args</code> and <code>kwargs</code>.</p> </li> <li> <code>*args</code>             (<code>args</code>, default:                 <code>()</code> )         \u2013          <p>Positional arguments passed to <code>loss_fn</code>.</p> </li> <li> <code>**kwargs</code>             (<code>kwargs</code>, default:                 <code>{}</code> )         \u2013          <p>Keyword arguments passed to <code>loss_fn</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ClosureFn</code>         \u2013          <p>A closure function that takes in a tensor of parameters with <code>shape=(n,)</code>, a boolean flag indicating whether to compute the gradient, and a boolean flag indicating whether to compute the Hessian. It returns a tuple of the loss value, the gradient, and the Hessian.</p> </li> </ul> Source code in <code>descent/utils/loss.py</code> <pre><code>def to_closure(\n    loss_fn: typing.Callable[typing.Concatenate[torch.Tensor, P], torch.Tensor],\n    *args: P.args,\n    **kwargs: P.kwargs,\n) -&gt; ClosureFn:\n    \"\"\"Convert a loss function to a closure function used by second-order optimizers.\n\n    Args:\n        loss_fn: The loss function to convert. This should take in a tensor of\n            parameters with ``shape=(n,)``, and optionally a set of ``args`` and\n            ``kwargs``.\n        *args: Positional arguments passed to `loss_fn`.\n        **kwargs: Keyword arguments passed to `loss_fn`.\n\n    Returns:\n        A closure function that takes in a tensor of parameters with ``shape=(n,)``,\n        a boolean flag indicating whether to compute the gradient, and a boolean flag\n        indicating whether to compute the Hessian. It returns a tuple of the loss\n        value, the gradient, and the Hessian.\n    \"\"\"\n\n    loss_fn_wrapped = functools.partial(loss_fn, *args, **kwargs)\n\n    def closure_fn(\n        x: torch.Tensor, compute_gradient: bool, compute_hessian: bool\n    ) -&gt; tuple[torch.Tensor, torch.Tensor | None, torch.Tensor | None]:\n        loss = loss_fn_wrapped(x)\n        gradient, hessian = None, None\n\n        if compute_hessian:\n            hessian = torch.autograd.functional.hessian(\n                loss_fn_wrapped, x, vectorize=True, create_graph=False\n            ).detach()\n        if compute_gradient:\n            (gradient,) = torch.autograd.grad(loss, x, create_graph=False)\n            gradient = gradient.detach()\n\n        return loss.detach(), gradient, hessian\n\n    return closure_fn\n</code></pre>"},{"location":"reference/utils/loss/#descent.utils.loss.approximate_hessian","title":"approximate_hessian","text":"<pre><code>approximate_hessian(x: Tensor, y_pred: Tensor)\n</code></pre> <p>Compute the outer product approximation of the hessian of a least squares loss function of the sum <code>sum((y_pred - y_ref)**2)</code>.</p> <p>Parameters:</p> <ul> <li> <code>x</code>             (<code>Tensor</code>)         \u2013          <p>The parameter tensor with <code>shape=(n_parameters,)</code>.</p> </li> <li> <code>y_pred</code>             (<code>Tensor</code>)         \u2013          <p>The values predicted using <code>x</code> with <code>shape=(n_predications,)</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li>         \u2013          <p>The outer product approximation of the hessian with ``shape=n_parameters</p> </li> </ul> Source code in <code>descent/utils/loss.py</code> <pre><code>def approximate_hessian(x: torch.Tensor, y_pred: torch.Tensor):\n    \"\"\"Compute the outer product approximation of the hessian of a least squares\n    loss function of the sum ``sum((y_pred - y_ref)**2)``.\n\n    Args:\n        x: The parameter tensor with ``shape=(n_parameters,)``.\n        y_pred: The values predicted using ``x`` with ``shape=(n_predications,)``.\n\n    Returns:\n        The outer product approximation of the hessian with ``shape=n_parameters\n    \"\"\"\n\n    y_pred_grad = [torch.autograd.grad(y, x, retain_graph=True)[0] for y in y_pred]\n    y_pred_grad = torch.stack(y_pred_grad, dim=0)\n\n    return (\n        2.0 * torch.einsum(\"bi,bj-&gt;bij\", y_pred_grad, y_pred_grad).sum(dim=0)\n    ).detach()\n</code></pre>"},{"location":"reference/utils/molecule/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> molecule","text":""},{"location":"reference/utils/molecule/#descent.utils.molecule","title":"molecule","text":"<p>Functions:</p> <ul> <li> <code>mol_to_smiles</code>           \u2013            <p>Convert a molecule to a SMILES string with atom mapping.</p> </li> </ul>"},{"location":"reference/utils/molecule/#descent.utils.molecule.mol_to_smiles","title":"mol_to_smiles","text":"<pre><code>mol_to_smiles(mol: Mol, canonical: bool = True) -&gt; str\n</code></pre> <p>Convert a molecule to a SMILES string with atom mapping.</p> <p>Parameters:</p> <ul> <li> <code>mol</code>             (<code>Mol</code>)         \u2013          <p>The molecule to convert.</p> </li> <li> <code>canonical</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to canonicalize the atom ordering prior to assigning map indices.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>         \u2013          <p>The SMILES string.</p> </li> </ul> Source code in <code>descent/utils/molecule.py</code> <pre><code>def mol_to_smiles(mol: \"Chem.Mol\", canonical: bool = True) -&gt; str:\n    \"\"\"Convert a molecule to a SMILES string with atom mapping.\n\n    Args:\n        mol: The molecule to convert.\n        canonical: Whether to canonicalize the atom ordering prior to assigning\n            map indices.\n\n    Returns:\n        The SMILES string.\n    \"\"\"\n    from rdkit import Chem\n\n    mol = Chem.AddHs(mol)\n\n    if canonical:\n        order = Chem.CanonicalRankAtoms(mol, includeChirality=True)\n        mol = Chem.RenumberAtoms(mol, list(order))\n\n    for atom in mol.GetAtoms():\n        atom.SetAtomMapNum(atom.GetIdx() + 1)\n\n    return Chem.MolToSmiles(mol)\n</code></pre>"},{"location":"reference/utils/reporting/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> reporting","text":""},{"location":"reference/utils/reporting/#descent.utils.reporting","title":"reporting","text":"<p>Utilities for reporting results.</p> <p>Functions:</p> <ul> <li> <code>mols_to_img</code>           \u2013            <p>Renders a set of molecules as an embeddable HTML image tag.</p> </li> <li> <code>figure_to_img</code>           \u2013            <p>Convert a matplotlib figure to an embeddable HTML image tag.</p> </li> <li> <code>print_potential_summary</code>           \u2013            <p>Print a summary of the potential parameters to the terminal.</p> </li> <li> <code>print_force_field_summary</code>           \u2013            <p>Print a summary of the force field parameters to the terminal.</p> </li> </ul>"},{"location":"reference/utils/reporting/#descent.utils.reporting.mols_to_img","title":"mols_to_img","text":"<pre><code>mols_to_img(\n    *smiles: str, width: int = 400, height: int = 200\n) -&gt; str\n</code></pre> <p>Renders a set of molecules as an embeddable HTML image tag.</p> <p>Parameters:</p> <ul> <li> <code>*smiles</code>             (<code>str</code>, default:                 <code>()</code> )         \u2013          <p>The SMILES patterns of the molecules to render.</p> </li> <li> <code>width</code>             (<code>int</code>, default:                 <code>400</code> )         \u2013          <p>The width of the image.</p> </li> <li> <code>height</code>             (<code>int</code>, default:                 <code>200</code> )         \u2013          <p>The height of the image.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>         \u2013          <p>The HTML image tag.</p> </li> </ul> Source code in <code>descent/utils/reporting.py</code> <pre><code>def mols_to_img(*smiles: str, width: int = 400, height: int = 200) -&gt; str:\n    \"\"\"Renders a set of molecules as an embeddable HTML image tag.\n\n    Args:\n        *smiles: The SMILES patterns of the molecules to render.\n        width: The width of the image.\n        height: The height of the image.\n\n    Returns:\n        The HTML image tag.\n    \"\"\"\n    from rdkit import Chem\n    from rdkit.Chem import Draw\n\n    assert len(smiles) &gt; 0\n\n    mol = _mol_from_smiles(smiles[0])\n\n    for pattern in smiles[1:]:\n        mol = Chem.CombineMols(mol, _mol_from_smiles(pattern))\n\n    mol = Draw.PrepareMolForDrawing(mol, forceCoords=True)\n\n    drawer = Draw.rdMolDraw2D.MolDraw2DSVG(width, height)\n    drawer.DrawMolecule(mol)\n    drawer.FinishDrawing()\n\n    data = base64.b64encode(drawer.GetDrawingText().encode()).decode()\n    return f'&lt;img src=\"data:image/svg+xml;base64,{data}\"&gt;&lt;/img&gt;'\n</code></pre>"},{"location":"reference/utils/reporting/#descent.utils.reporting.figure_to_img","title":"figure_to_img","text":"<pre><code>figure_to_img(figure: Figure) -&gt; str\n</code></pre> <p>Convert a matplotlib figure to an embeddable HTML image tag.</p> <p>Parameters:</p> <ul> <li> <code>figure</code>             (<code>Figure</code>)         \u2013          <p>The figure to convert.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>         \u2013          <p>The HTML image tag.</p> </li> </ul> Source code in <code>descent/utils/reporting.py</code> <pre><code>def figure_to_img(figure: \"pyplot.Figure\") -&gt; str:\n    \"\"\"Convert a matplotlib figure to an embeddable HTML image tag.\n\n    Args:\n        figure: The figure to convert.\n\n    Returns:\n        The HTML image tag.\n    \"\"\"\n\n    with io.BytesIO() as stream:\n        figure.savefig(stream, format=\"svg\")\n        data = base64.b64encode(stream.getvalue()).decode()\n\n    return f'&lt;img src=\"data:image/svg+xml;base64,{data}\"&gt;&lt;/img&gt;'\n</code></pre>"},{"location":"reference/utils/reporting/#descent.utils.reporting.print_potential_summary","title":"print_potential_summary","text":"<pre><code>print_potential_summary(potential: TensorPotential)\n</code></pre> <p>Print a summary of the potential parameters to the terminal.</p> <p>Parameters:</p> <ul> <li> <code>potential</code>             (<code>TensorPotential</code>)         \u2013          <p>The potential.</p> </li> </ul> Source code in <code>descent/utils/reporting.py</code> <pre><code>def print_potential_summary(potential: smee.TensorPotential):\n    \"\"\"Print a summary of the potential parameters to the terminal.\n\n    Args:\n        potential: The potential.\n    \"\"\"\n    import pandas\n\n    parameter_rows = []\n\n    for key, value in zip(potential.parameter_keys, potential.parameters.detach()):\n        row = {\"ID\": _format_parameter_id(key.id)}\n        row.update(\n            {\n                f\"{col}{_format_unit(potential.parameter_units[idx])}\": f\"{value[idx].item():.4f}\"\n                for idx, col in enumerate(potential.parameter_cols)\n            }\n        )\n        parameter_rows.append(row)\n\n    print(f\" {potential.type} \".center(88, \"=\"), flush=True)\n    print(f\"fn={potential.fn}\", flush=True)\n\n    if potential.attributes is not None:\n        attribute_rows = [\n            {\n                f\"{col}{_format_unit(potential.attribute_units[idx])}\": f\"{potential.attributes[idx].item():.4f} \"\n                for idx, col in enumerate(potential.attribute_cols)\n            }\n        ]\n        print(\"\")\n        print(\"attributes=\", flush=True)\n        print(\"\")\n        print(pandas.DataFrame(attribute_rows).to_string(index=False), flush=True)\n\n    print(\"\")\n    print(\"parameters=\", flush=True)\n    print(\"\")\n    print(pandas.DataFrame(parameter_rows).to_string(index=False), flush=True)\n</code></pre>"},{"location":"reference/utils/reporting/#descent.utils.reporting.print_force_field_summary","title":"print_force_field_summary","text":"<pre><code>print_force_field_summary(force_field: TensorForceField)\n</code></pre> <p>Print a summary of the force field parameters to the terminal.</p> <p>Parameters:</p> <ul> <li> <code>force_field</code>             (<code>TensorForceField</code>)         \u2013          <p>The force field.</p> </li> </ul> Source code in <code>descent/utils/reporting.py</code> <pre><code>def print_force_field_summary(force_field: smee.TensorForceField):\n    \"\"\"Print a summary of the force field parameters to the terminal.\n\n    Args:\n        force_field: The force field.\n    \"\"\"\n\n    if force_field.v_sites is not None:\n        print_v_site_summary(force_field.v_sites)\n        print(\"\")\n\n    for potential in force_field.potentials:\n        print_potential_summary(potential)\n        print(\"\")\n</code></pre>"}]}